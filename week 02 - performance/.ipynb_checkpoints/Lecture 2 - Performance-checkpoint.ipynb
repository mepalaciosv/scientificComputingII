{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e01e0b-a039-4f38-84cb-ac7ba5b45626",
   "metadata": {},
   "source": [
    "<h1 style=\"color: teal\">Lecture 2 - Performance</h1>\n",
    "\n",
    "<strong style=\"color: #1B2A49\">E. Margarita Palacios Vargas<br>\n",
    "Fundación Universitaria Konrad Lorenz</strong>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b693cf-83ad-4557-8c8b-f1bfd7790301",
   "metadata": {},
   "source": [
    "<h2 style=\"color: teal\">Performance</h2>\n",
    "\n",
    "We already discussed that <strong>performance measurements are stochastic</strong> — i.e., repeated runs of the same program can produce slightly different execution times.\n",
    "\n",
    "Recapping, we can measure:\n",
    "\n",
    "- **Counts** — how often an event occurs\n",
    "- **Duration** — the time taken for some interval or operation\n",
    "- **Size** — the amount of data or memory used by a variable\n",
    "\n",
    "Next, we will look at how to measure performance in <strong>Python</strong>.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7cba59-f646-4dcc-b491-57bb37b193ec",
   "metadata": {},
   "source": [
    "<h2 style=\"color: teal\">2.1. Measuring CPU time</h2>\n",
    "\n",
    "<h4>1. <code>timeit</code></h4>\n",
    "\n",
    "The <code>timeit</code> module can be used to measure the execution time of small pieces of code.\n",
    "\n",
    "If you go to the address of your Python script on the terminal (e.g., the \"examples\" folder where this document is), you can time the execution of a function inside of it :\n",
    "\n",
    "```bash\n",
    "python -m timeit -s \"import collatz\" \"collatz.main()\"\n",
    "# Example output:\n",
    "# 1 loop, best of 5: 174 msec per loop\n",
    "```\n",
    "The \"-m\" and \"-s\" are flags, here is the meaning of some of them:\n",
    "\n",
    "- **`-s \"SETUP\"`** → Setup code, runs once before timing (e.g., imports, variable definitions).  \n",
    "- **`-n N`** → Number of loops per trial (how many times to run the snippet each trial).  \n",
    "- **`-r R`** → Number of repeats (how many trials to do, default 5).  \n",
    "- **`-p P`** → Precision of results (digits after decimal in output).  \n",
    "- **`-t`** → Use `time.time()` (wall clock, default on Unix).  \n",
    "- **`-c`** → Use `time.perf_counter()` (high-resolution timer, default on Windows).  \n",
    "- **`-h`** → Show help message with all options.\n",
    "\n",
    "In a <strong>Jupyter Notebook</strong>, you can use the <strong>magic command</strong> <code>%timeit</code>:\n",
    "\n",
    "```bash\n",
    "%timeit my_function()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f67665-851b-45df-a12f-92e27c9659b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%timeit [x**4 for x in range(10000)]\n",
    "%timeit np.arange(10000)**4 # Just as expected, numpy aranges run faster than Python core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ba0e4-9897-4800-9965-7cb1f06be996",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "- *Magic commands* are called like that because they’re special shortcuts provided by IPython/Jupyter (using `%` or `%%`) that aren’t part of standard Python but add extra functionality like timing, running shell commands, or controlling the notebook.  \n",
    "- *IPython* (Interactive Python) is an enhanced Python shell that powers Jupyter, offering features like tab completion, inline help, rich output, and magic commands on top of the standard interpreter.\n",
    "- **`%timeit`** → one line, **`%%timeit`** → whole cell\n",
    "\n",
    "As you can see, an approach to beat the stochastic CPU time is to use statistics. The output of this magic function shows the mean and standard deviation after running the subsequent code a number of times.\n",
    "\n",
    "We can also measure the execution CPU time of functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd621119-086c-495f-b7b6-abb89371018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit # Now it applies to the entire cell\n",
    "def sum2d(arr):\n",
    "    M, N = arr.shape\n",
    "    result = 0.0\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            result += arr[i,j]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30c587e-2f99-4bc7-8939-58bd6ae1351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The previous script does not define the function\n",
    "def sum2d(arr):\n",
    "    M, N = arr.shape\n",
    "    result = 0.0\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            result += arr[i,j]\n",
    "    return result\n",
    "\n",
    "a = np.ones((2048, 2048)) \n",
    "a.size == 2048 ** 2 # Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91e070-7a2a-4d0a-bfce-f08edf5a820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sum2d(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27785bd-2b70-46f9-b84f-eb6f9737de64",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h4>2. <code>njit from numba</code></h4>\n",
    "\n",
    "The <code>njit</code> decorator from the <strong>Numba</strong> library performs <strong>Just-In-Time (JIT)</strong> compilation of Python functions to optimized machine code, often achieving speeds comparable to compiled languages like C or Fortran.\n",
    "\n",
    "**Note:** `@njit` is equivalent to `@jit(nopython = True)` and is now the recommended usage. The `nopython = True` flag forces Numba to compile to pure machine code (fastest) instead of falling back to Python. The older `@jit` form is still supported, but its *object mode fallback* behavior has been deprecated. See the [Numba documentation](https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be98bb7-d665-4804-af12-ccab2c47c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "a = np.ones((2048, 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c096384-ed48-4e9e-9e06-d17aae36338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def sum2dv3(arr):\n",
    "    M, N = arr.shape\n",
    "    result = 0.0\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            result += arr[i,j]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5defdc-7f1a-4dee-84ef-b4938f3dccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sum2d(a)\n",
    "%timeit sum2dv3(a) # njit's compiled code runs faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd0df9a-e62c-4898-b8a6-99de10facf46",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h4>3. <code>numexpr</code></h4>\n",
    "\n",
    "The `numexpr` library in Python is designed to efficiently evaluate numerical expressions on arrays. It provides a way to accelerate numerical computations, especially those involving large arrays, by optimizing memory usage, utilizing multiple CPU cores and avoiding the creation of large temporal arrays. I can also often outperform Numpy. You can check its documentation [here](https://numexpr.readthedocs.io/en/latest/user_guide.html).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab651b-f770-443e-8e4d-670e1a83704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d666da-8806-4a07-95f2-2d6b5c890e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(100000)\n",
    "b = np.random.rand(100000)\n",
    "\n",
    "%timeit np.sin(a) + np.log(b)\n",
    "%timeit ne.evaluate(\"sin(a) + log(b)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83477d05-78bb-4a57-bd26-ba18cedfe99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit 2*a + 3*b\n",
    "%timeit ne.evaluate(\"2*a + 3*b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f938949-6eb9-4a43-9634-9db5ab947431",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2 style=\"color: teal\">2.2. Measuring size</h2>\n",
    "\n",
    "Inspecting attributes like the folowing reveal how arrays are stored in memory, which is useful for understanding memory usage and optimizing performance. This is not considered *as* important as it was several decades ago because of Moore's law."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b6408e-eedc-4f0f-875e-ceb5aae27f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.3, 2.4, 3.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef019ab7-0fa1-41e4-8ee7-c02c63cb1061",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.data # Memory Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82fc32f-ad88-4ef6-8ede-d655ecff477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'data' = A 2-tuple whose first argument is a Python integer\n",
    "# that points to the data-area storing the array contents.\n",
    "x.__array_interface__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9befd8b-9588-4822-a48b-148e85def62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size (number of elements of the array)\n",
    "x.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7cb8d8-ccbe-49a0-8008-0744bef0b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory size of one array element (in bytes)\n",
    "x.itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a30564-c355-4786-869e-f6ca11ebda13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory size of the full (in bytes)\n",
    "x.itemsize * x.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc085b2-0f54-4da6-bca2-9101577b6c21",
   "metadata": {},
   "source": [
    "<h2 style=\"color: teal\">2.3. Profiling</h2>\n",
    "\n",
    "Profiling in Python means analyzing the performance of your code to identify bottlenecks and areas that can be optimized. Python provides several built-in tools for profiling. Here, we will cover some that are considered native (<i>i.e., they do not require additional software</i>).\n",
    "\n",
    "---\n",
    "\n",
    "<h4>1. <code>cProfile</code></h4>\n",
    "\n",
    "<strong>Syntax (on bash):</strong>\n",
    "```bash\n",
    "python -m cProfile collatz.py\n",
    "python -m cProfile -o stats.out collatz.py # To output to a file\n",
    "```\n",
    "\n",
    "This prints a lot of unnecessary elements, but we can consume it as well from Jupyter with shorter results regarding code and stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47594246-3cd4-4e72-9225-1c495dfd02d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats\n",
    "\n",
    "# Run and show results\n",
    "cProfile.run(\"print('Hello profiling!')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eccdbb-5fee-4fa8-b129-98fab4e5e513",
   "metadata": {},
   "source": [
    "What are we seeing?\n",
    "- `ncalls`: This column shows the number of times each function was called during the execution of the program.\n",
    "- `tottime`: This column indicates the total time (in seconds) spent in each function excluding time spent in its subfunctions. It's the \"internal\" time spent exclusively in the function itself.\n",
    "- `percall`: This column shows the average time (in seconds) spent in each function call, calculated as tottime / ncalls.\n",
    "- `cumtime`: This column represents the cumulative time (in seconds) spent in the function and all its subfunctions. It includes the time spent in the function itself and all the functions called from it.\n",
    "- `percall` (cumtime): Average cumulative time (in seconds) per primitive call, calculated as cumtime / primitive calls. (If there’s no recursion, primitive calls ≈ ncalls, so the numbers will look the same.)\n",
    "- `filename:lineno(function)`: This column provides information about the location of the function in your code, including the filename, line number, and function name.\n",
    "\n",
    "The output is generally sorted by the cumtime column, which helps you quickly identify functions that consume the most overall time. These are potential candidates for optimization. You will want to look at functions with **high cumtime and ncalls values**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bdedb6-5a19-4cd3-a5cf-c5c9612de739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a file\n",
    "cProfile.run(\"print('Hello profiling!')\", \"profiler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ad9cf-d8bb-4adb-a2c9-6829cfbe1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect saved results\n",
    "stats = pstats.Stats(\"profiler\")\n",
    "stats.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96932517-a8b5-4193-9141-fe5ae445eb24",
   "metadata": {},
   "source": [
    "`cProfile` can also be invoked as a module to profile a given script (or module). The syntax is as follows.\n",
    "```bash\n",
    "python -m cProfile [-o output_file] [-s sort_order] (-m module | myscript.py)\n",
    "python -m cProfile examples/factorial.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4130815-04c6-4bae-a16c-c93945b65a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Module to work with bash\n",
    "os.system(\"type examples\\\\Example0.py\") # Windows\n",
    "os.system(\"cat examples/Example0.py\") # Mac/Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e300df3-d717-4c77-8521-314f31fa28df",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h4>2. <code>profile</code></h4>\n",
    "\n",
    "The `profile` module is another built-in profiler that provides a higher-level interface for profiling your code. It outputs information about function calls and their time consumption. You can use the `profile` module to profile specific parts of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac490b1-eea1-45d2-a395-0381f51e3130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9406696-f4a5-4be0-a865-6f7ef2c63fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 is a one...\n",
      "         34 function calls in 0.031 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.031    0.031    0.031    0.031 2287880165.py:1(main)\n",
      "        2    0.000    0.000    0.000    0.000 :0(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 :0(append)\n",
      "        2    0.000    0.000    0.000    0.000 :0(get)\n",
      "        2    0.000    0.000    0.000    0.000 :0(getpid)\n",
      "        1    0.000    0.000    0.000    0.000 :0(is_done)\n",
      "        2    0.000    0.000    0.000    0.000 :0(isinstance)\n",
      "        2    0.000    0.000    0.000    0.000 :0(items)\n",
      "        2    0.000    0.000    0.000    0.000 :0(len)\n",
      "        1    0.000    0.000    0.000    0.000 :0(print)\n",
      "        1    0.000    0.000    0.000    0.000 :0(setprofile)\n",
      "        2    0.000    0.000    0.000    0.000 :0(write)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:138(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:259(schedule)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:505(parent_header)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:550(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:577(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:655(write)\n",
      "        1    0.000    0.000    0.031    0.031 profile:0(<function main at 0x000002886B7016C0>)\n",
      "        0    0.000             0.000          profile:0(profiler)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:626(send)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1136(is_alive)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:605(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 tz.py:74(utcoffset)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main(): # This is Example2.py\n",
    "\tx = [1.0] * (2048 * 2048) \n",
    "\ta = str(x[0]) \n",
    "\ta += \" is a one...\" \n",
    "\tdel x\t\t\t\n",
    "\tprint(a)\n",
    "\n",
    "profiler = profile.Profile()\n",
    "profiler.runcall(main)\n",
    "profiler.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ddbf3-8a25-461f-b68f-4307f38b8974",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h4>3. <code>line_profiler</code></h4>\n",
    "\n",
    "We are still getting an output similar to `cProfile`. To get an output of the performance line-by-line, we should do something else.\n",
    "1. Install `line_profiler` using `pip/anaconda`.\n",
    "```bash\n",
    "pip install line-profiler\n",
    "```\n",
    "2. On the .py file that you want to analyze, put the decorator `@profile` above the function that you want to profile.\n",
    "3. Use `kernprof.py` (found [here](https://github.com/pyutils/line_profiler/blob/main/kernprof.py), but also inside `examples`) on your .py file.\n",
    "```bash\n",
    "python kernprof.py -l Example1.py\n",
    "```\n",
    "4. Execute the command the terminal tells you to continue with:\n",
    "```bash\n",
    "C:\\Users\\Margarita\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m line_profiler -rmt \"Example1.py.lprof\"\n",
    "```\n",
    "The result looks something like this:\n",
    "```console\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 0.0112843 s\n",
    "File: Example1.py\n",
    "Function: main at line 1\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     1                                           @profile\n",
    "     2                                           def main():\n",
    "     3         1       6471.7   6471.7     57.4         x = [1.0]*(2048*2048) \n",
    "     4         1          9.4      9.4      0.1         a = str(x[0]) \n",
    "     5         1          1.7      1.7      0.0         a += \" is a one...\" \n",
    "     6         1       4610.5   4610.5     40.9         del x\n",
    "     7         1        191.0    191.0      1.7         print(a)\n",
    "\n",
    "  0.01 seconds - Example1.py:1 - main\n",
    "```\n",
    "\n",
    "Try to do this for the example files in `examples/`.\n",
    "\n",
    "If we were to do something similar in the terminal we'd use `prun` or `snakeviz`, which shows a nice interactive graph. For `snakeviz` we have to do a little instalation first:\n",
    "```bash\n",
    "conda install snakeviz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fa529bd-90e1-468b-a35e-2ee5eb299e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(a, b, c):\n",
    "\tprint(\"a = \", a)\n",
    "\tprint(\"b = \", b)\n",
    "\tprint(np.dot(a, b))\n",
    "\tprint(a @ b)\n",
    "\n",
    "a = np.array([[1, 2], [4, 3]])\n",
    "b = np.array([[1, 2], [4, 3]])\n",
    "c = np.arange(2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc85bc89-a194-453c-bb7d-ae9914025796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  [[1 2]\n",
      " [4 3]]\n",
      "b =  [[1 2]\n",
      " [4 3]]\n",
      "[[ 9  8]\n",
      " [16 17]]\n",
      "[[ 9  8]\n",
      " [16 17]]\n",
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         863 function calls (827 primitive calls) in 0.003 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "     28/4    0.000    0.000    0.000    0.000 arrayprint.py:829(recurser)\n",
       "       12    0.000    0.000    0.000    0.000 iostream.py:655(write)\n",
       "        8    0.000    0.000    0.000    0.000 socket.py:626(send)\n",
       "        1    0.000    0.000    0.002    0.002 {built-in method builtins.exec}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        8    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "        1    0.000    0.000    0.002    0.002 2853867017.py:3(main)\n",
       "        4    0.000    0.000    0.000    0.000 arrayprint.py:1274(__init__)\n",
       "      2/0    0.000    0.000    0.000          {built-in method select.select}\n",
       "       16    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
       "        4    0.000    0.000    0.001    0.000 arrayprint.py:557(_array2string)\n",
       "        4    0.000    0.000    0.002    0.000 {built-in method builtins.print}\n",
       "      184    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
       "        4    0.000    0.000    0.001    0.000 arrayprint.py:595(array2string)\n",
       "        4    0.000    0.000    0.000    0.000 arrayprint.py:50(_make_options_dict)\n",
       "        8    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\n",
       "        4    0.000    0.000    0.000    0.000 arrayprint.py:486(_get_format_function)\n",
       "        3    0.000    0.000    0.000    0.000 attrsettr.py:66(_get_attr_opt)\n",
       "        4    0.000    0.000    0.001    0.000 arrayprint.py:540(wrapper)\n",
       "       16    0.000    0.000    0.000    0.000 arrayprint.py:779(_extendLine)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
       "       16    0.000    0.000    0.000    0.000 arrayprint.py:793(_extendLine_pretty)\n",
       "        1    0.000    0.000    0.000    0.000 queues.py:225(get)\n",
       "        4    0.000    0.000    0.001    0.000 arrayprint.py:1675(_array_str_implementation)\n",
       "    93/89    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:703(send_multipart)\n",
       "        4    0.000    0.000    0.000    0.000 arrayprint.py:820(_formatArray)\n",
       "        8    0.000    0.000    0.000    0.000 enum.py:1596(__or__)\n",
       "       39    0.000    0.000    0.000    0.000 enum.py:1589(_get_value)\n",
       "        3    0.000    0.000    0.000    0.000 attrsettr.py:43(__getattr__)\n",
       "       16    0.000    0.000    0.000    0.000 arrayprint.py:1289(__call__)\n",
       "        4    0.000    0.000    0.000    0.000 arrayprint.py:436(_get_formatdict)\n",
       "       24    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
       "       20    0.000    0.000    0.000    0.000 {method 'get' of '_contextvars.ContextVar' objects}\n",
       "       12    0.000    0.000    0.000    0.000 iostream.py:505(parent_header)\n",
       "        1    0.000    0.000    0.000    0.000 asyncio.py:231(add_callback)\n",
       "       12    0.000    0.000    0.000    0.000 iostream.py:550(_is_master_process)\n",
       "        4    0.000    0.000    0.000    0.000 arrayprint.py:444(<lambda>)\n",
       "        4    0.000    0.000    0.000    0.000 fromnumeric.py:3080(max)\n",
       "       12    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
       "       17    0.000    0.000    0.000    0.000 enum.py:695(__call__)\n",
       "       12    0.000    0.000    0.000    0.000 iostream.py:577(_schedule_flush)\n",
       "      2/0    0.000    0.000    0.000          base_events.py:1962(_run_once)\n",
       "       16    0.000    0.000    0.000    0.000 {method 'splitlines' of 'str' objects}\n",
       "        2    0.000    0.000    0.000    0.000 zmqstream.py:686(_update_handler)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:278(_really_send)\n",
       "        4    0.000    0.000    0.000    0.000 fromnumeric.py:3225(min)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:259(schedule)\n",
       "        2    0.000    0.000    0.000    0.000 queue.py:115(empty)\n",
       "       12    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
       "       12    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
       "        2    0.000    0.000    0.000    0.000 zmqstream.py:663(_rebuild_io_state)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:774(recv_multipart)\n",
       "        5    0.000    0.000    0.000    0.000 enum.py:1607(__and__)\n",
       "       13    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
       "        1    0.000    0.000    0.000    0.000 threading.py:1136(is_alive)\n",
       "       14    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
       "        3    0.000    0.000    0.000    0.000 typing.py:426(inner)\n",
       "        1    0.000    0.000    0.000    0.000 queues.py:173(qsize)\n",
       "      2/0    0.000    0.000    0.000          selectors.py:310(select)\n",
       "       17    0.000    0.000    0.000    0.000 enum.py:1156(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 abc.py:121(__subclasscheck__)\n",
       "       14    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
       "        1    0.000    0.000    0.000    0.000 base_events.py:852(_call_soon)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:276(<lambda>)\n",
       "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1390(_handle_fromlist)\n",
       "        1    0.000    0.000    0.000    0.000 events.py:36(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 queues.py:256(get_nowait)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:213(_is_master_process)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
       "        1    0.000    0.000    0.002    0.002 <string>:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:138(_event_pipe)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
       "        2    0.000    0.000    0.000    0.000 typing.py:1665(__subclasscheck__)\n",
       "        1    0.000    0.000    0.000    0.000 events.py:87(_run)\n",
       "        1    0.000    0.000    0.000    0.000 zmqstream.py:583(_handle_events)\n",
       "        2    0.000    0.000    0.000    0.000 base_events.py:772(time)\n",
       "        1    0.000    0.000    0.000    0.000 zmqstream.py:624(_handle_recv)\n",
       "        2    0.000    0.000    0.000    0.000 typing.py:1374(__instancecheck__)\n",
       "        1    0.000    0.000    0.000    0.000 base_events.py:823(call_soon)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
       "        2    0.000    0.000    0.000    0.000 typing.py:1443(__hash__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _contextvars.copy_context}\n",
       "        2    0.000    0.000    0.000    0.000 queue.py:267(_qsize)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
       "        2    0.000    0.000    0.000    0.000 zmqstream.py:542(sending)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'run' of '_contextvars.Context' objects}\n",
       "        4    0.000    0.000    0.000    0.000 fromnumeric.py:3220(_min_dispatcher)\n",
       "      2/0    0.000    0.000    0.000          selectors.py:304(_select)\n",
       "        1    0.000    0.000    0.000    0.000 ioloop.py:750(_run_callback)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
       "        1    0.000    0.000    0.000    0.000 queues.py:322(_consume_expired)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:216(_check_mp_mode)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
       "        3    0.000    0.000    0.000    0.000 zmqstream.py:538(receiving)\n",
       "        1    0.000    0.000    0.000    0.000 zmqstream.py:556(_run_callback)\n",
       "        4    0.000    0.000    0.000    0.000 fromnumeric.py:3075(_max_dispatcher)\n",
       "        1    0.000    0.000    0.000    0.000 tz.py:74(utcoffset)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'is_done' of '_thread._ThreadHandle' objects}\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:157(_handle_event)\n",
       "        1    0.000    0.000    0.000    0.000 queues.py:59(_set_timeout)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method time.monotonic}\n",
       "        1    0.000    0.000    0.000    0.000 multiarray.py:757(dot)\n",
       "        1    0.000    0.000    0.000    0.000 selector_events.py:740(_process_events)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:255(closed)\n",
       "        2    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _asyncio.get_running_loop}\n",
       "        2    0.000    0.000    0.000    0.000 base_events.py:2060(get_debug)\n",
       "        1    0.000    0.000    0.000    0.000 zmqstream.py:694(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 threading.py:605(is_set)\n",
       "        1    0.000    0.000    0.000    0.000 base_events.py:554(_check_closed)\n",
       "        1    0.000    0.000    0.000    0.000 typing.py:2371(cast)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%prun main(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9302235a-4b15-46da-b9ef-69573904b4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  [[1 2]\n",
      " [4 3]]\n",
      "b =  [[1 2]\n",
      " [4 3]]\n",
      "[[ 9  8]\n",
      " [16 17]]\n",
      "[[ 9  8]\n",
      " [16 17]]\n",
      " \n",
      "*** Profile stats marshalled to file 'C:\\\\Users\\\\MARGAR~1\\\\AppData\\\\Local\\\\Temp\\\\tmpzc75zjo9'.\n",
      "Embedding SnakeViz in this document...\n",
      "<function display at 0x0000028867F596C0>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe id='snakeviz-2b45fa4a-9730-11f0-809a-745d22062856' frameborder=0 seamless width='100%' height='1000'></iframe>\n",
       "<script>document.getElementById(\"snakeviz-2b45fa4a-9730-11f0-809a-745d22062856\").setAttribute(\"src\", \"http://\" + document.location.hostname + \":8080/snakeviz/C%3A%5CUsers%5CMARGAR~1%5CAppData%5CLocal%5CTemp%5Ctmpzc75zjo9\")</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext snakeviz\n",
    "%snakeviz main(a, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715dd4f0-4039-4ef5-bc9f-863752804773",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
